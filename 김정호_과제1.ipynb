{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1단계: 환경 설정 및 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "y0QZRERS11Nx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZMXh7mitybV2"
      },
      "outputs": [],
      "source": [
        "# 1단계: 환경 설정 및 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from collections import Counter\n",
        "import xgboost as xgb\n",
        "\n",
        "classification_data_path = \"./sample_data/Loan_Default.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2단계: 데이터 로드 및 전처리"
      ],
      "metadata": {
        "id": "ut4YrVQL2W2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BinomialClassificationDataLoader:\n",
        "    def __init__(self, path):\n",
        "        self.data = pd.read_csv(path)  # CSV 파일 로드\n",
        "        self.label_column = 'Status'  # 타겟 컬럼명 지정\n",
        "        self.features = None\n",
        "        self.labels = None\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
        "        self.scaler = None  # 스케일러 객체 저장용\n",
        "\n",
        "    def preprocess(self):\n",
        "        df = self.data.copy()  # 원본 데이터 복사본 생성\n",
        "\n",
        "        # 1) 결측치 처리 방법 비교 (mean, median, mode) 결과를 토대로 mean으로 처리\n",
        "        for col in df.select_dtypes(include=np.number).columns:\n",
        "            df[col] = df[col].fillna(df[col].mean())  # 수치형 컬럼은 평균으로 결측치 대체\n",
        "\n",
        "        # 2) 모델에 의미 없는 컬럼 제거 (Loan_ID, Customer_ID, Overdue_Days)\n",
        "        df = df.drop(columns=['Loan_ID', 'Customer_ID', 'Overdue_Days'], errors='ignore')\n",
        "\n",
        "        # 3) 범주형 변수 원-핫 인코딩 (ID 컬럼 제외)\n",
        "        df = pd.get_dummies(df.drop(['ID'], axis=1))\n",
        "\n",
        "        # 4) 불균형 데이터 해소를 위해 Under Sampling 적용\n",
        "        label_counts = df[self.label_column].value_counts()\n",
        "        min_class = label_counts.idxmin()  # 소수 클래스 라벨\n",
        "        min_count = label_counts.min()  # 소수 클래스 데이터 수\n",
        "\n",
        "        balanced_parts = []\n",
        "        for label in label_counts.index:\n",
        "            subset = df[df[self.label_column] == label]\n",
        "            if label == min_class:\n",
        "                balanced_parts.append(subset)  # 소수 클래스는 모두 사용\n",
        "            else:\n",
        "                # 다수 클래스는 소수 클래스 수만큼 랜덤 샘플링 (Under Sampling)\n",
        "                balanced_parts.append(subset.sample(n=min_count, random_state=42))\n",
        "        balanced_df = pd.concat(balanced_parts).sample(frac=1, random_state=42).reset_index(drop=True)  # 섞기\n",
        "\n",
        "        # 5) 스케일링 방법 비교 (StandardScaler vs MinMaxScaler)\n",
        "        X = balanced_df.drop(self.label_column, axis=1).values\n",
        "        y = balanced_df[self.label_column].values.astype(int)\n",
        "        X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        scaler_std = StandardScaler()  # 평균 0, 표준편차 1로 변환\n",
        "        scaler_minmax = MinMaxScaler()  # 0~1 사이로 변환\n",
        "\n",
        "        X_train_std = scaler_std.fit_transform(X_train_raw)\n",
        "        X_test_std = scaler_std.transform(X_test_raw)\n",
        "\n",
        "        X_train_minmax = scaler_minmax.fit_transform(X_train_raw)\n",
        "        X_test_minmax = scaler_minmax.transform(X_test_raw)\n",
        "\n",
        "        # Logistic Regression 모델로 스케일러별 성능 비교\n",
        "        tmp_model = LogisticRegression(penalty=None, class_weight='balanced', max_iter=1000, random_state=42)\n",
        "\n",
        "        tmp_model.fit(X_train_std, y_train)\n",
        "        y_pred_std = tmp_model.predict(X_test_std)\n",
        "        f1_std = f1_score(y_test, y_pred_std)\n",
        "\n",
        "        tmp_model.fit(X_train_minmax, y_train)\n",
        "        y_pred_minmax = tmp_model.predict(X_test_minmax)\n",
        "        f1_minmax = f1_score(y_test, y_pred_minmax)\n",
        "\n",
        "        # print(\"StandardScaler F1-score:\", f1_std)\n",
        "        # print(\"MinMaxScaler F1-score:\", f1_minmax)\n",
        "\n",
        "        # 성능이 좋은 StandardScaler 선택 후 최종 적용\n",
        "        self.scaler = scaler_std\n",
        "\n",
        "        # Stratified Split 다시 수행 + 선택한 스케일러 적용\n",
        "        X_train, X_test, self.y_train, self.y_test = train_test_split(\n",
        "            balanced_df.drop(self.label_column, axis=1).values,\n",
        "            balanced_df[self.label_column].values.astype(int),\n",
        "            test_size=0.2,\n",
        "            random_state=42,\n",
        "            stratify=balanced_df[self.label_column]\n",
        "        )\n",
        "        self.X_train = self.scaler.fit_transform(X_train)\n",
        "        self.X_test = self.scaler.transform(X_test)\n",
        "\n",
        "        # 데이터 형태 및 분포 출력\n",
        "        print(f\"Train shape: {self.X_train.shape}, Test shape: {self.X_test.shape}\")\n",
        "        print(f\"Train label distribution: {Counter(self.y_train)}\")\n",
        "        print(f\"Test label distribution: {Counter(self.y_test)}\")\n",
        "\n",
        "    def get_sample_weights(self):\n",
        "        # 클래스 불균형 보정을 위한 샘플 가중치 계산\n",
        "        # balanced 옵션으로 각 클래스의 가중치를 자동 조정\n",
        "        return compute_sample_weight(class_weight='balanced', y=self.y_train)"
      ],
      "metadata": {
        "id": "tO0lagdY2WR_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3단계: 평가 함수"
      ],
      "metadata": {
        "id": "7dpfA2wu99C4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(name, y_true, y_pred):\n",
        "    # 평가 결과 출력용 함수\n",
        "    print(f\"\\n{name} Evaluation Results\")\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall   : {rec:.4f}\")\n",
        "    print(f\"F1 Score : {f1:.4f}\")\n",
        "    print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "2JnfZ8Rj-CtP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4단계: 모델 정의 클래스들"
      ],
      "metadata": {
        "id": "yrRykA5J-KNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeModel:\n",
        "    def __init__(self):\n",
        "        # 하이퍼파라미터 튜닝 결과 반영\n",
        "        self.model = DecisionTreeClassifier(\n",
        "            max_depth=5,\n",
        "            min_samples_leaf=10,\n",
        "            class_weight='balanced',  # 불균형 보정\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.model.fit(X, y)  # 모델 학습\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)  # 예측값 반환\n",
        "\n",
        "\n",
        "class RandomForestModel:\n",
        "    def __init__(self):\n",
        "        # 하이퍼파라미터 튜닝 결과 반영\n",
        "        self.model = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=7,\n",
        "            class_weight='balanced',\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "\n",
        "class GBDTModel:\n",
        "    def __init__(self):\n",
        "        # 하이퍼파라미터 튜닝 결과 반영\n",
        "        self.model = GradientBoostingClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=5,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    def train(self, X, y, sample_weights):\n",
        "        # sample_weight 매개변수로 가중치 적용 가능\n",
        "        self.model.fit(X, y, sample_weight=sample_weights)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "\n",
        "class XGBoostModel:\n",
        "    def __init__(self, scale_pos_weight):\n",
        "        # scale_pos_weight로 불균형 조정\n",
        "        self.model = xgb.XGBClassifier(\n",
        "            n_estimators=100,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=4,\n",
        "            scale_pos_weight=scale_pos_weight,\n",
        "            use_label_encoder=False,\n",
        "            eval_metric='logloss',\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    def train(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)"
      ],
      "metadata": {
        "id": "0Gfiu019-NVf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5단계: 파라미터 튜닝"
      ],
      "metadata": {
        "id": "RmUEUTfoKW0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F1-score를 기반으로 모델 성능을 평가하기 위한 Scorer 생성\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "# ---------------- Decision Tree 튜닝 ----------------\n",
        "def tune_decision_tree(X, y):\n",
        "    # 그리드 서치를 위한 파라미터 후보 목록 설정\n",
        "    param_grid = {\n",
        "        'max_depth': [3, 4, 5, 6, 7],              # 트리의 최대 깊이 후보\n",
        "        'min_samples_leaf': [5, 10, 20]            # 리프 노드가 되기 위한 최소 샘플 수\n",
        "    }\n",
        "\n",
        "    # 클래스 불균형 문제를 고려하여 class_weight='balanced'로 설정\n",
        "    dt = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "    # F1-score를 기준으로 교차검증을 통해 최적 파라미터 탐색\n",
        "    grid = GridSearchCV(dt, param_grid, scoring=f1_scorer, cv=3, n_jobs=-1)\n",
        "\n",
        "    # 모델 학습 (그리드 서치 수행)\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # 최적 파라미터 및 최고 F1-score 출력\n",
        "    print(\"DecisionTree 최적 파라미터:\", grid.best_params_)\n",
        "    print(\"최고 F1 점수:\", grid.best_score_)\n",
        "\n",
        "    # 최적 모델 반환\n",
        "    return grid.best_estimator_\n",
        "\n",
        "# ---------------- Random Forest 튜닝 ----------------\n",
        "def tune_random_forest(X, y):\n",
        "    # 파라미터 후보 설정\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],           # 트리 개수 후보\n",
        "        'max_depth': [5, 7, 10]                   # 트리 최대 깊이 후보\n",
        "    }\n",
        "\n",
        "    # 클래스 불균형 처리 + 재현성 확보\n",
        "    rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "    # F1-score 기준으로 그리드 서치 수행\n",
        "    grid = GridSearchCV(rf, param_grid, scoring=f1_scorer, cv=3, n_jobs=-1)\n",
        "\n",
        "    # 모델 학습\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # 최적 파라미터 및 성능 출력\n",
        "    print(\"RandomForest 최적 파라미터:\", grid.best_params_)\n",
        "    print(\"최고 F1 점수:\", grid.best_score_)\n",
        "\n",
        "    # 최적 모델 반환\n",
        "    return grid.best_estimator_\n",
        "\n",
        "# ---------------- GBDT 튜닝 ----------------\n",
        "def tune_gbdt(X, y):\n",
        "    # 파라미터 후보 설정\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],        # 학습률 후보\n",
        "        'max_depth': [3, 5, 7]                    # 트리 최대 깊이 후보\n",
        "    }\n",
        "\n",
        "    # GBDT 모델 설정 (기본 트리 수는 50)\n",
        "    gbdt = GradientBoostingClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "    # 그리드 서치 수행\n",
        "    grid = GridSearchCV(gbdt, param_grid, scoring=f1_scorer, cv=3, n_jobs=-1)\n",
        "\n",
        "    # 학습 및 탐색\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # 최적 파라미터 및 최고 성능 출력\n",
        "    print(\"GBDT 최적 파라미터:\", grid.best_params_)\n",
        "    print(\"최고 F1 점수:\", grid.best_score_)\n",
        "\n",
        "    # 최적 모델 반환\n",
        "    return grid.best_estimator_\n",
        "\n",
        "# ---------------- XGBoost 튜닝 ----------------\n",
        "def tune_xgboost(X, y, scale_pos_weight):\n",
        "    # 파라미터 후보 설정\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],       # 학습률 후보\n",
        "        'max_depth': [3, 4, 5]                    # 트리 최대 깊이 후보\n",
        "    }\n",
        "\n",
        "    # XGBoost 분류기 설정\n",
        "    xgb_clf = xgb.XGBClassifier(\n",
        "        n_estimators=50,                        # 트리 수\n",
        "        scale_pos_weight=scale_pos_weight,      # 클래스 불균형 비율 설정\n",
        "        use_label_encoder=False,                # 경고 제거\n",
        "        eval_metric='logloss',                  # 평가 지표 설정\n",
        "        random_state=42                         # 재현성 확보\n",
        "    )\n",
        "\n",
        "    # 그리드 서치를 통해 파라미터 최적화\n",
        "    grid = GridSearchCV(xgb_clf, param_grid, scoring=f1_scorer, cv=3, n_jobs=-1)\n",
        "\n",
        "    # 모델 학습\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    # 최적 파라미터 및 F1 성능 출력\n",
        "    print(\"XGBoost 최적 파라미터:\", grid.best_params_)\n",
        "    print(\"최고 F1 점수:\", grid.best_score_)\n",
        "\n",
        "    # 최적 모델 반환\n",
        "    return grid.best_estimator_"
      ],
      "metadata": {
        "id": "fB3eH08TKbwj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6단계: 실행부"
      ],
      "metadata": {
        "id": "5fIqdmia-RTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    loader = BinomialClassificationDataLoader(classification_data_path)\n",
        "    loader.preprocess()\n",
        "\n",
        "    print(\"\\n--- Logistic Regression 평가 ---\")\n",
        "    logreg = LogisticRegression(penalty=None, class_weight='balanced', max_iter=1000, random_state=42)\n",
        "    logreg.fit(loader.X_train, loader.y_train)\n",
        "    y_pred_logreg = logreg.predict(loader.X_test)\n",
        "    evaluate_model(\"Logistic Regression\", loader.y_test, y_pred_logreg)\n",
        "\n",
        "    print(\"\\n--- Decision Tree 하이퍼파라미터 튜닝 및 평가 ---\")\n",
        "    best_dt = tune_decision_tree(loader.X_train, loader.y_train)\n",
        "    y_pred_dt = best_dt.predict(loader.X_test)\n",
        "    evaluate_model(\"Decision Tree_Tuned\", loader.y_test, y_pred_dt)\n",
        "\n",
        "    print(\"\\n--- Random Forest 하이퍼파라미터 튜닝 및 평가 ---\")\n",
        "    best_rf = tune_random_forest(loader.X_train, loader.y_train)\n",
        "    y_pred_rf = best_rf.predict(loader.X_test)\n",
        "    evaluate_model(\"Random Forest_Tuned\", loader.y_test, y_pred_rf)\n",
        "\n",
        "    print(\"\\n--- GBDT 하이퍼파라미터 튜닝 및 평가 ---\")\n",
        "    best_gbdt = tune_gbdt(loader.X_train, loader.y_train)\n",
        "    y_pred_gbdt = best_gbdt.predict(loader.X_test)\n",
        "    evaluate_model(\"Gradient Boosted Trees_Tuned\", loader.y_test, y_pred_gbdt)\n",
        "\n",
        "    print(\"\\n--- XGBoost 하이퍼파라미터 튜닝 및 평가 ---\")\n",
        "    neg, pos = np.bincount(loader.y_train)\n",
        "    scale_pos_weight = neg / pos\n",
        "    best_xgb = tune_xgboost(loader.X_train, loader.y_train, scale_pos_weight)\n",
        "    y_pred_xgb = best_xgb.predict(loader.X_test)\n",
        "    evaluate_model(\"XGBoost_Tuned\", loader.y_test, y_pred_xgb)\n",
        "\n",
        "\n",
        "    #결과 분석 : LR 외 성능지표가 1에 수렴함. 데이터셋 불균형 해결, GridSearchCV를 통한 교차검증, train-test 데이터 구분 등 하였으나, 파라미터 튜닝 등 모델이 복잡할 가능성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QmgUcPH-QCn",
        "outputId": "e1fc64a1-fb2a-4ee8-ac24-e238db81ee72"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (58622, 70), Test shape: (14656, 70)\n",
            "Train label distribution: Counter({np.int64(1): 29311, np.int64(0): 29311})\n",
            "Test label distribution: Counter({np.int64(1): 7328, np.int64(0): 7328})\n",
            "\n",
            "--- Logistic Regression 평가 ---\n",
            "\n",
            "Logistic Regression Evaluation Results\n",
            "Accuracy : 0.7765\n",
            "Precision: 0.8669\n",
            "Recall   : 0.6532\n",
            "F1 Score : 0.7451\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.90      0.80      7328\n",
            "           1       0.87      0.65      0.75      7328\n",
            "\n",
            "    accuracy                           0.78     14656\n",
            "   macro avg       0.79      0.78      0.77     14656\n",
            "weighted avg       0.79      0.78      0.77     14656\n",
            "\n",
            "\n",
            "--- Decision Tree 하이퍼파라미터 튜닝 및 평가 ---\n",
            "DecisionTree 최적 파라미터: {'max_depth': 3, 'min_samples_leaf': 5}\n",
            "최고 F1 점수: 0.9999317778682048\n",
            "\n",
            "Decision Tree_Tuned Evaluation Results\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      7328\n",
            "           1       1.00      1.00      1.00      7328\n",
            "\n",
            "    accuracy                           1.00     14656\n",
            "   macro avg       1.00      1.00      1.00     14656\n",
            "weighted avg       1.00      1.00      1.00     14656\n",
            "\n",
            "\n",
            "--- Random Forest 하이퍼파라미터 튜닝 및 평가 ---\n",
            "RandomForest 최적 파라미터: {'max_depth': 5, 'n_estimators': 100}\n",
            "최고 F1 점수: 1.0\n",
            "\n",
            "Random Forest_Tuned Evaluation Results\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      7328\n",
            "           1       1.00      1.00      1.00      7328\n",
            "\n",
            "    accuracy                           1.00     14656\n",
            "   macro avg       1.00      1.00      1.00     14656\n",
            "weighted avg       1.00      1.00      1.00     14656\n",
            "\n",
            "\n",
            "--- GBDT 하이퍼파라미터 튜닝 및 평가 ---\n",
            "GBDT 최적 파라미터: {'learning_rate': 0.01, 'max_depth': 3}\n",
            "최고 F1 점수: 0.9999317778682048\n",
            "\n",
            "Gradient Boosted Trees_Tuned Evaluation Results\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      7328\n",
            "           1       1.00      1.00      1.00      7328\n",
            "\n",
            "    accuracy                           1.00     14656\n",
            "   macro avg       1.00      1.00      1.00     14656\n",
            "weighted avg       1.00      1.00      1.00     14656\n",
            "\n",
            "\n",
            "--- XGBoost 하이퍼파라미터 튜닝 및 평가 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [14:51:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost 최적 파라미터: {'learning_rate': 0.01, 'max_depth': 3}\n",
            "최고 F1 점수: 0.9999488360194423\n",
            "\n",
            "XGBoost_Tuned Evaluation Results\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      7328\n",
            "           1       1.00      1.00      1.00      7328\n",
            "\n",
            "    accuracy                           1.00     14656\n",
            "   macro avg       1.00      1.00      1.00     14656\n",
            "weighted avg       1.00      1.00      1.00     14656\n",
            "\n"
          ]
        }
      ]
    }
  ]
}